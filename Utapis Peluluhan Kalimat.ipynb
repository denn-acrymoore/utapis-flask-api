{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0jirWpkHtwt",
        "outputId": "55cd0596-fb78-44e5-c997-a8c66967af91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.8/dist-packages (1.0.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.8/dist-packages (4.6.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.8/dist-packages (0.3.1)\n"
          ]
        }
      ],
      "source": [
        "#Library yang digunakan\n",
        "!pip install sastrawi\n",
        "!pip install beautifulsoup4\n",
        "!pip install anyascii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUXhS27mHxBg",
        "outputId": "6efccc62-0196-4a51-bcfa-caade66e405f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#Import yang diperlukan\n",
        "import string\n",
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "#nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "#sastrawi\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "#beautyfulsoup4\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "#anyascii\n",
        "from anyascii import anyascii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGQ_fR2BEe8G"
      },
      "outputs": [],
      "source": [
        "def tokenized_kalimat(berita):\n",
        "  test_raw_data = re.sub(r\"(\\\\n|\\\\r)\", r\"\\n\", berita)\n",
        "  test_raw_data = re.sub(r\"(\\\\t|\\\\f|\\\\v)\", r\" \", test_raw_data)\n",
        "\n",
        "  # Ekstraksi konten dari HTML Rich Text dengan BeautifulSoup4\n",
        "  soup = BeautifulSoup(test_raw_data, \"html.parser\")\n",
        "  news_html_free = soup.get_text()\n",
        "\n",
        "  # Ubah semua karakter unicode menjadi ASCII yang paling mendekati\n",
        "  news_html_free = anyascii(news_html_free)\n",
        "\n",
        "  #tokenizing kalimat\n",
        "  sent_tokenized = nltk.tokenize.sent_tokenize(news_html_free)\n",
        "\n",
        "  return sent_tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BgvVl6FHz2W"
      },
      "source": [
        "Fungsi dibawah digunakan untuk mempreproses datanya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHfVS8P1H2-t"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(kalimat):\n",
        "  sentence_processed = []\n",
        "\n",
        "  #mengubah kalimat menjadi huruf kecil\n",
        "  lower_case = kalimat.lower()\n",
        "\n",
        "  #menghilangkan kelebihan whitespace/karakter kosong\n",
        "  whitespace_removed = lower_case.strip()\n",
        "\n",
        "  # menghilangkan tanda baca\n",
        "  punctuation_removed = whitespace_removed.translate(str.maketrans(\"\",\"\",string.punctuation))\n",
        "\n",
        "  word_tokenized = nltk.tokenize.word_tokenize(punctuation_removed)\n",
        "\n",
        "  return word_tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FjSTHFAIC91"
      },
      "source": [
        "Fungsi dibawah adalah formula jaccard yang digunakan untuk menghitung similarity setiap kata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkPGvbbXIBkd"
      },
      "outputs": [],
      "source": [
        "def jaccard_similarity(list1, list2):\n",
        "    s1 = set(list1)\n",
        "    s2 = set(list2)\n",
        "    return float(len(s1.intersection(s2)) / len(s1.union(s2)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg9Yu7A7Jdkv"
      },
      "source": [
        "berikut adalah fungsi untuk melakukan perhitungan similaritas setiap kata terhadap data yang dimiliki "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5QLqcFkJliS"
      },
      "outputs": [],
      "source": [
        "def hitung_similarity(hasil_preproses, data):\n",
        "  y = 0\n",
        "  factory = StemmerFactory()\n",
        "  stemmer = factory.create_stemmer()\n",
        "  word_send = []\n",
        "\n",
        "  for kalimat in hasil_preproses:\n",
        "\n",
        "    words_temp = []\n",
        "    words_berita = preprocess_data(kalimat)\n",
        "    \n",
        "    for words in words_berita:\n",
        "      is_true = True\n",
        "      y = y + 1\n",
        "      if stemmer.stem(words)[0] in CONSTANT:\n",
        "        for data_words in data:\n",
        "          if abs(len(words) - len(data_words)) <= 1:\n",
        "            if stemmer.stem(words) == stemmer.stem(data_words):\n",
        "              x = jaccard_similarity([*data_words], [*words])\n",
        "              if x >= 0.75 and x <= 0.99:\n",
        "                is_true = False\n",
        "              else: \n",
        "                pass\n",
        "            else: \n",
        "              pass\n",
        "      else:\n",
        "        pass\n",
        "      words_temp.append({'words': words, 'is_true':is_true})\n",
        "\n",
        "    word_send.append(words_temp)\n",
        "  return word_send"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkGwINcDIIBv",
        "outputId": "77047a87-96b1-4641-a32e-081174c3438b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: docx2txt in /usr/local/lib/python3.8/dist-packages (0.8)\n"
          ]
        }
      ],
      "source": [
        "#Contoh Berita\n",
        "# test_raw_data = \"\"\"<p>kalimat labil pertama</p>\n",
        "# <p>kalimat kedua &lt &amp &#342;</p>\n",
        "# <p>kalimat&nbsp;ketiga & ketiga juga</p>\n",
        "# <p>kalimat &nbsp; keempat</p>\n",
        "# <p>kalimat <b>kel<i>i</i>ma</b></p>\n",
        "# <p>kalimatÂ keenam mempasarkan</a>\n",
        "# \"\"\"\n",
        "!pip install docx2txt\n",
        "import docx2txt\n",
        "\n",
        "# berita = docx2txt.process(\"beritatest1.docx\")\n",
        "berita = 'Budi berhasil mensamarkan bekas luka dengan mentarik'\n",
        "\n",
        "\n",
        "#Konstanta diperlukan karena peluluhan hanya terjadi pada kata dengan kata dasar S,P,T, dan K.\n",
        "CONSTANT = ['s','p','t','k']\n",
        "\n",
        "#Membaca dataset yang telah dicrawl, merupakan kata-kata yang benar.\n",
        "dataset = pd.read_excel('kata_yang_benar.xlsx')\n",
        "data = dataset[\"kata benar\"].to_numpy()\n",
        "# data = ['mengatakan','penagihan']\n",
        "\n",
        "# pakai looping zip(t1,t2) untuk return datanya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KY5NzhQFMSG",
        "outputId": "d6d84c72-7f9a-4b24-c605-b34a73debb19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Budi berhasil mensamarkan bekas luka dengan mentarik']\n"
          ]
        }
      ],
      "source": [
        "sentence_tokenized = tokenized_kalimat(berita)\n",
        "print(sentence_tokenized)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JudbzXpJ8Bw",
        "outputId": "9dee9038-aa70-4176-b011-9b953876c189"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "test similarity kata ke 3 :  0.75\n",
            "Kata mensamarkan tidak sesuai dengan kata menyamarkan\n",
            "test similarity kata ke 7 :  0.875\n",
            "Kata mentarik tidak sesuai dengan kata menarik\n",
            "[[{'words': 'budi', 'is_true': True}, {'words': 'berhasil', 'is_true': True}, {'words': 'mensamarkan', 'is_true': False}, {'words': 'bekas', 'is_true': True}, {'words': 'luka', 'is_true': True}, {'words': 'dengan', 'is_true': True}, {'words': 'mentarik', 'is_true': False}]]\n"
          ]
        }
      ],
      "source": [
        "x = hitung_similarity(sentence_tokenized, data)\n",
        "print(x)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10 (tags/v3.9.10:f2f3f53, Jan 17 2022, 15:14:21) [MSC v.1929 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "e43443016109f8e07ba36c94bbf6e03a77e9057c4a8bbb44685ec070104ef455"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
